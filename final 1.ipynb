{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "248cc8eb-7c9a-4dca-a676-a2b6d34c4d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4508b5b2-5006-4d51-b121-8ddf287a03c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 210 car images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Path to car images\n",
    "car_images_path = r'C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test'\n",
    "\n",
    "# Load car images\n",
    "car_images = []\n",
    "for filename in os.listdir(car_images_path):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):  # Add other formats if needed\n",
    "        image_path = os.path.join(car_images_path, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            car_images.append(image)\n",
    "\n",
    "print(f\"Loaded {len(car_images)} car images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39ab07a9-ad0b-43a9-9b25-22069e262511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 900 license plate images.\n"
     ]
    }
   ],
   "source": [
    "# Path to license plate images\n",
    "license_plate_images_path = r'C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\Licplatesdetection_train\\license_plates_detection_train'\n",
    "\n",
    "# Load license plate images\n",
    "license_plate_images = []\n",
    "for filename in os.listdir(license_plate_images_path):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):  # Add other formats if needed\n",
    "        image_path = os.path.join(license_plate_images_path, filename)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load in grayscale for character recognition\n",
    "        if image is not None:\n",
    "            license_plate_images.append(image)\n",
    "\n",
    "print(f\"Loaded {len(license_plate_images)} license plate images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d597ba6-a794-4640-ad84-12cae28f746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_car_image(image, target_size=(128, 128)):\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    return image\n",
    "\n",
    "preprocessed_car_images = [preprocess_car_image(img) for img in car_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "711cc2ed-9d58-46f6-a587-ee5eb0b6fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_license_plate(image, target_size=(64, 64)):\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    return image\n",
    "\n",
    "preprocessed_license_plates = [preprocess_license_plate(img) for img in license_plate_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33592a9e-bf6b-482f-b2b1-9b223f71f1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1000.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1001.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1002.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1003.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1004.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1005.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1006.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1007.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1008.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1009.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1010.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1011.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1012.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1013.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1014.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1015.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1016.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1017.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1018.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1019.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1020.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1021.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1022.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1023.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1024.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1025.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1026.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1027.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1028.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1029.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1030.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1031.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1032.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1033.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1034.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1035.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1036.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1037.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1038.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1039.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1040.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1041.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1042.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1043.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1044.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1045.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1046.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1047.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1048.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1049.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1050.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1051.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1052.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1053.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1054.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1055.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1056.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1057.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1058.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1059.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1060.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1061.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1062.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1063.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1064.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1065.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1066.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1067.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1068.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1069.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1070.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1071.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1072.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1073.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1074.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1075.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1076.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1077.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1078.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1079.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1080.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1081.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1082.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1083.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1084.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1085.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1086.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1087.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1088.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1089.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1090.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1091.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1092.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1093.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1094.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1095.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1096.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1098.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1099.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1100.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1101.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1102.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1103.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1104.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1105.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1106.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1107.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1108.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1109.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1110.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1111.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1112.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\1113.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\901.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\902.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\903.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\904.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\905.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\906.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\907.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\908.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\909.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\910.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\911.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\912.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\913.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\914.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\915.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\917.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\918.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\919.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\920.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\921.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\922.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\923.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\924.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\925.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\926.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\927.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\928.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\929.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\930.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\931.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\932.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\933.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\934.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\935.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\936.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\937.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\938.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\939.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\940.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\941.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\942.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\943.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\944.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\945.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\946.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\947.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\948.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\949.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\950.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\951.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\952.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\953.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\954.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\955.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\956.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\957.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\958.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\959.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\960.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\961.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\962.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\963.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\964.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\965.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\966.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\967.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\968.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\969.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\970.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\971.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\972.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\973.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\974.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\975.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\976.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\977.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\978.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\979.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\981.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\982.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\983.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\984.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\985.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\986.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\987.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\988.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\989.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\990.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\991.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\992.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\993.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\994.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\995.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\996.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\997.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\998.jpg...\n",
      "Processing C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test\\999.jpg...\n",
      "Automatic annotation process completed.\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the EasyOCR reader\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Path to the folder containing car images\n",
    "car_images_path = r'C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test'\n",
    "\n",
    "# Output CSV file to save annotations\n",
    "output_csv = 'automatic_annotations.csv'\n",
    "\n",
    "# Write headers to the CSV file\n",
    "with open(output_csv, 'w') as file:\n",
    "    file.write(\"filename,xmin,ymin,xmax,ymax,text,confidence\\n\")\n",
    "\n",
    "# Loop through each image in the folder\n",
    "for filename in os.listdir(car_images_path):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        image_path = os.path.join(car_images_path, filename)\n",
    "        print(f\"Processing {image_path}...\")\n",
    "\n",
    "        # Load the image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Error: Unable to load image at {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Perform text detection\n",
    "        results = reader.readtext(image)\n",
    "\n",
    "        # Save detected text and bounding boxes to CSV\n",
    "        with open(output_csv, 'a') as file:\n",
    "            for result in results:\n",
    "                bbox, text, confidence = result\n",
    "                xmin, ymin = map(int, bbox[0])\n",
    "                xmax, ymax = map(int, bbox[2])\n",
    "                file.write(f\"{filename},{xmin},{ymin},{xmax},{ymax},{text},{confidence}\\n\")\n",
    "\n",
    "print(\"Automatic annotation process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2e977ae-245d-488e-89de-495d4766d5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3108ba85-beff-4ed4-9259-4687420e5447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid bounding box for 1066.jpg: (218, 449, 326, 449)\n",
      "Bounding box out of bounds for 1092.jpg: (766, 7, 855, 45)\n",
      "Invalid bounding box for 907.jpg: (185, 198, 312, 198)\n",
      "Preprocessed 402 license plates.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the annotations\n",
    "annotations = pd.read_csv('automatic_annotations.csv')\n",
    "\n",
    "# Path to the folder containing car images\n",
    "car_images_path = r'C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test'\n",
    "\n",
    "# Path to save cropped license plate images\n",
    "output_folder = 'cropped_license_plates'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Preprocess and save cropped license plates\n",
    "cropped_images = []\n",
    "text_labels = []\n",
    "\n",
    "for index, row in annotations.iterrows():\n",
    "    filename = row['filename']\n",
    "    xmin, ymin, xmax, ymax = row['xmin'], row['ymin'], row['xmax'], row['ymax']\n",
    "    text = row['text']\n",
    "\n",
    "    # Load the image\n",
    "    image_path = os.path.join(car_images_path, filename)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        continue\n",
    "\n",
    "    # Get image dimensions\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # Validate bounding box coordinates\n",
    "    if xmin >= xmax or ymin >= ymax:\n",
    "        print(f\"Invalid bounding box for {filename}: ({xmin}, {ymin}, {xmax}, {ymax})\")\n",
    "        continue\n",
    "    if xmin < 0 or ymin < 0 or xmax > width or ymax > height:\n",
    "        print(f\"Bounding box out of bounds for {filename}: ({xmin}, {ymin}, {xmax}, {ymax})\")\n",
    "        continue\n",
    "\n",
    "    # Crop the license plate\n",
    "    license_plate = image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "    # Check if the cropped image is valid\n",
    "    if license_plate.size == 0:\n",
    "        print(f\"Empty license plate for {filename}: ({xmin}, {ymin}, {xmax}, {ymax})\")\n",
    "        continue\n",
    "\n",
    "    # Resize and normalize the license plate\n",
    "    license_plate = cv2.resize(license_plate, (128, 64))  # Adjust size as needed\n",
    "    license_plate = license_plate / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "    # Save the cropped license plate\n",
    "    output_path = os.path.join(output_folder, f\"cropped_{filename}\")\n",
    "    cv2.imwrite(output_path, license_plate * 255)  # Save as 8-bit image\n",
    "\n",
    "    # Append to lists\n",
    "    cropped_images.append(license_plate)\n",
    "    text_labels.append(text)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "cropped_images = np.array(cropped_images)\n",
    "text_labels = np.array(text_labels)\n",
    "\n",
    "print(f\"Preprocessed {len(cropped_images)} license plates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42c6135c-c062-4171-b9ea-fee3c9285d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid bounding box for 1066.jpg: (218, 449, 326, 449)\n",
      "Bounding box out of bounds for 1092.jpg: (766, 7, 855, 45)\n",
      "Invalid bounding box for 907.jpg: (185, 198, 312, 198)\n",
      "Preprocessed 402 license plates.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the annotations\n",
    "annotations = pd.read_csv('automatic_annotations.csv')\n",
    "\n",
    "# Path to the folder containing car images\n",
    "car_images_path = r'C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test'\n",
    "\n",
    "# Path to save cropped license plate images\n",
    "output_folder = 'cropped_license_plates'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Preprocess and save cropped license plates\n",
    "cropped_images = []\n",
    "text_labels = []\n",
    "\n",
    "for index, row in annotations.iterrows():\n",
    "    filename = row['filename']\n",
    "    xmin, ymin, xmax, ymax = row['xmin'], row['ymin'], row['xmax'], row['ymax']\n",
    "    text = row['text']\n",
    "\n",
    "    # Load the image\n",
    "    image_path = os.path.join(car_images_path, filename)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        continue\n",
    "\n",
    "    # Get image dimensions\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # Validate bounding box coordinates\n",
    "    if xmin >= xmax or ymin >= ymax:\n",
    "        print(f\"Invalid bounding box for {filename}: ({xmin}, {ymin}, {xmax}, {ymax})\")\n",
    "        continue\n",
    "    if xmin < 0 or ymin < 0 or xmax > width or ymax > height:\n",
    "        print(f\"Bounding box out of bounds for {filename}: ({xmin}, {ymin}, {xmax}, {ymax})\")\n",
    "        continue\n",
    "\n",
    "    # Crop the license plate\n",
    "    license_plate = image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "    # Check if the cropped image is valid\n",
    "    if license_plate.size == 0:\n",
    "        print(f\"Empty license plate for {filename}: ({xmin}, {ymin}, {xmax}, {ymax})\")\n",
    "        continue\n",
    "\n",
    "    # Resize and normalize the license plate\n",
    "    license_plate = cv2.resize(license_plate, (128, 64))  # Adjust size as needed\n",
    "    license_plate = license_plate / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "    # Save the cropped license plate\n",
    "    output_path = os.path.join(output_folder, f\"cropped_{filename}\")\n",
    "    cv2.imwrite(output_path, license_plate * 255)  # Save as 8-bit image\n",
    "\n",
    "    # Append to lists\n",
    "    cropped_images.append(license_plate)\n",
    "    text_labels.append(text)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "cropped_images = np.array(cropped_images)\n",
    "text_labels = np.array(text_labels)\n",
    "\n",
    "print(f\"Preprocessed {len(cropped_images)} license plates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5d984e1-746f-401c-80fd-0f73855b6f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26880</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,440,768</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">48,375</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26880\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m3,440,768\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m)                 │          \u001b[38;5;34m48,375\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,508,535</span> (13.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,508,535\u001b[0m (13.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,508,535</span> (13.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,508,535\u001b[0m (13.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 196ms/step - accuracy: 0.0000e+00 - loss: 6.0797 - val_accuracy: 0.0000e+00 - val_loss: 5.9396\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 135ms/step - accuracy: 0.0161 - loss: 5.9162 - val_accuracy: 0.0000e+00 - val_loss: 5.9759\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.0278 - loss: 5.9089 - val_accuracy: 0.0000e+00 - val_loss: 5.9815\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.0171 - loss: 5.8763 - val_accuracy: 0.0000e+00 - val_loss: 6.0456\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.0069 - loss: 5.8376 - val_accuracy: 0.0000e+00 - val_loss: 6.2194\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.0225 - loss: 5.7384 - val_accuracy: 0.0000e+00 - val_loss: 6.5616\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.0314 - loss: 5.6154 - val_accuracy: 0.0000e+00 - val_loss: 6.9030\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.0568 - loss: 5.3300 - val_accuracy: 0.0123 - val_loss: 7.1328\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.0883 - loss: 5.0367 - val_accuracy: 0.0123 - val_loss: 7.6816\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 144ms/step - accuracy: 0.1901 - loss: 4.5236 - val_accuracy: 0.0247 - val_loss: 8.2008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2269f8d1670>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Encode text labels into numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(text_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(cropped_images, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the CNN model\n",
    "def create_recognition_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create and train the model\n",
    "input_shape = (64, 128, 3)  # Adjust based on your image size\n",
    "num_classes = len(label_encoder.classes_)\n",
    "recognition_model = create_recognition_model(input_shape, num_classes)\n",
    "recognition_model.summary()\n",
    "\n",
    "# Train the model\n",
    "recognition_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41b05d01-97e5-4001-aa10-41231c4d0345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.0280 - loss: 8.0994\n",
      "Test Accuracy: 2.47%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
      "Predicted Text: 3973\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = recognition_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Predict on a sample image\n",
    "sample_image = X_test[0]\n",
    "predicted_label = recognition_model.predict(np.expand_dims(sample_image, axis=0))\n",
    "predicted_text = label_encoder.inverse_transform([np.argmax(predicted_label)])[0]\n",
    "print(f\"Predicted Text: {predicted_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de943cd6-4e51-4a13-958d-a4eff7abd596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'license_plate_recognition_model.h5'.\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "recognition_model.save('license_plate_recognition_model.h5')\n",
    "print(\"Model saved as 'license_plate_recognition_model.h5'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a53c56c-4591-4b76-b07d-dbbbbbc966d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
      "Predicted License Plate Text: 7355-55906\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('license_plate_recognition_model.h5')\n",
    "\n",
    "# Function to recognize license plate text\n",
    "def recognize_license_plate(image_path):\n",
    "    # Load and preprocess the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (128, 64))  # Resize to match model input\n",
    "    image = image / 255.0  # Normalize\n",
    "\n",
    "    # Predict the text\n",
    "    predicted_label = model.predict(np.expand_dims(image, axis=0))\n",
    "    predicted_text = label_encoder.inverse_transform([np.argmax(predicted_label)])[0]\n",
    "    return predicted_text\n",
    "\n",
    "# Test on a new image\n",
    "new_image_path = r'C:\\Users\\user\\Desktop\\licplt new.jpeg'\n",
    "predicted_text = recognize_license_plate(new_image_path)\n",
    "print(f\"Predicted License Plate Text: {predicted_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f3e0b7-2a5d-44c6-b78a-8858aa4c7268",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Encode text labels into numerical labels\u001b[39;00m\n\u001b[0;32m      8\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m----> 9\u001b[0m encoded_labels \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(text_labels)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets\u001b[39;00m\n\u001b[0;32m     12\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(cropped_images, encoded_labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text_labels' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Encode text labels into numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(text_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(cropped_images, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the CNN model\n",
    "def create_recognition_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create and train the model\n",
    "input_shape = (64, 128, 3)  # Adjust based on your image size\n",
    "num_classes = len(label_encoder.classes_)\n",
    "recognition_model = create_recognition_model(input_shape, num_classes)\n",
    "recognition_model.summary()\n",
    "\n",
    "# Train the model\n",
    "recognition_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a1246d-701e-4401-beba-84ce10a408a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid bounding box for 1066.jpg: (218, 449, 326, 449)\n",
      "Bounding box out of bounds for 1092.jpg: (766, 7, 855, 45)\n",
      "Invalid bounding box for 907.jpg: (185, 198, 312, 198)\n",
      "Preprocessed 402 license plates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26880</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,440,768</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">48,375</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26880\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m3,440,768\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m)                 │          \u001b[38;5;34m48,375\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,508,535</span> (13.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,508,535\u001b[0m (13.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,508,535</span> (13.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,508,535\u001b[0m (13.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 178ms/step - accuracy: 0.0000e+00 - loss: 6.1236 - val_accuracy: 0.0000e+00 - val_loss: 5.9392\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.0055 - loss: 5.9237 - val_accuracy: 0.0000e+00 - val_loss: 5.9590\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - accuracy: 0.0000e+00 - loss: 5.9093 - val_accuracy: 0.0000e+00 - val_loss: 6.0203\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.0000e+00 - loss: 5.8758 - val_accuracy: 0.0123 - val_loss: 6.0908\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.0138 - loss: 5.7985 - val_accuracy: 0.0247 - val_loss: 6.2238\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.0288 - loss: 5.6963 - val_accuracy: 0.0123 - val_loss: 6.7829\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.0269 - loss: 5.5603 - val_accuracy: 0.0123 - val_loss: 6.9620\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.0680 - loss: 5.2888 - val_accuracy: 0.0123 - val_loss: 7.2197\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - accuracy: 0.0931 - loss: 5.0434 - val_accuracy: 0.0247 - val_loss: 7.5639\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.1062 - loss: 4.6888 - val_accuracy: 0.0123 - val_loss: 7.9810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'license_plate_recognition_model.h5'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Step 1: Load the annotations\n",
    "annotations = pd.read_csv('automatic_annotations.csv')\n",
    "\n",
    "# Step 2: Preprocess the data\n",
    "car_images_path = r'C:\\Users\\user\\Downloads\\DATA SCIENTIST_ASSIGNMENT-20250226T162947Z-001\\DATA SCIENTIST_ASSIGNMENT\\test\\test\\test'\n",
    "output_folder = 'cropped_license_plates'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "cropped_images = []\n",
    "text_labels = []\n",
    "\n",
    "for index, row in annotations.iterrows():\n",
    "    filename = row['filename']\n",
    "    xmin, ymin, xmax, ymax = row['xmin'], row['ymin'], row['xmax'], row['ymax']\n",
    "    text = row['text']\n",
    "\n",
    "    # Load the image\n",
    "    image_path = os.path.join(car_images_path, filename)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        continue\n",
    "\n",
    "    # Validate bounding box coordinates\n",
    "    height, width, _ = image.shape\n",
    "    if xmin >= xmax or ymin >= ymax:\n",
    "        print(f\"Invalid bounding box for {filename}: ({xmin}, {ymin}, {xmax}, {ymax})\")\n",
    "        continue\n",
    "    if xmin < 0 or ymin < 0 or xmax > width or ymax > height:\n",
    "        print(f\"Bounding box out of bounds for {filename}: ({xmin}, {ymin}, {xmax}, {ymax})\")\n",
    "        continue\n",
    "\n",
    "    # Crop the license plate\n",
    "    license_plate = image[ymin:ymax, xmin:xmax]\n",
    "    if license_plate.size == 0:\n",
    "        print(f\"Empty license plate for {filename}: ({xmin}, {ymin}, {xmax}, {ymax})\")\n",
    "        continue\n",
    "\n",
    "    # Resize and normalize the license plate\n",
    "    license_plate = cv2.resize(license_plate, (128, 64))  # Resize to match model input\n",
    "    license_plate = license_plate / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "    # Save the cropped license plate\n",
    "    output_path = os.path.join(output_folder, f\"cropped_{filename}\")\n",
    "    cv2.imwrite(output_path, license_plate * 255)  # Save as 8-bit image\n",
    "\n",
    "    # Append to lists\n",
    "    cropped_images.append(license_plate)\n",
    "    text_labels.append(text)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "cropped_images = np.array(cropped_images)\n",
    "text_labels = np.array(text_labels)\n",
    "\n",
    "print(f\"Preprocessed {len(cropped_images)} license plates.\")\n",
    "\n",
    "# Step 3: Encode text labels into numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(text_labels)\n",
    "\n",
    "# Step 4: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(cropped_images, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Define the CNN model\n",
    "def create_recognition_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Step 6: Create and train the model\n",
    "input_shape = (64, 128, 3)  # Adjust based on your image size\n",
    "num_classes = len(label_encoder.classes_)\n",
    "recognition_model = create_recognition_model(input_shape, num_classes)\n",
    "recognition_model.summary()\n",
    "\n",
    "# Train the model\n",
    "recognition_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Step 7: Save the model\n",
    "recognition_model.save('license_plate_recognition_model.h5')\n",
    "print(\"Model saved as 'license_plate_recognition_model.h5'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69264023-133a-4614-8c02-4b2f9fae3d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
      "Predicted License Plate Text: 1733 59116\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('license_plate_recognition_model.h5')\n",
    "\n",
    "# Function to recognize license plate text\n",
    "def recognize_license_plate(image_path):\n",
    "    # Load and preprocess the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        return None\n",
    "\n",
    "    # Resize and normalize the image\n",
    "    image = cv2.resize(image, (128, 64))  # Resize to match model input\n",
    "    image = image / 255.0  # Normalize\n",
    "\n",
    "    # Predict the text\n",
    "    predicted_label = model.predict(np.expand_dims(image, axis=0))\n",
    "    predicted_text = label_encoder.inverse_transform([np.argmax(predicted_label)])[0]\n",
    "    return predicted_text\n",
    "\n",
    "# Test on a new image\n",
    "new_image_path = r'C:\\Users\\user\\Desktop\\licplt new.jpeg'\n",
    "predicted_text = recognize_license_plate(new_image_path)\n",
    "if predicted_text is not None:\n",
    "    print(f\"Predicted License Plate Text: {predicted_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "211a0ef3-f10b-4536-8dfc-594752f9d2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
      "Predicted License Plate Text: [122_;2171]\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('license_plate_recognition_model.h5')\n",
    "\n",
    "# Function to recognize license plate text\n",
    "def recognize_license_plate(image_path):\n",
    "    # Load and preprocess the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}\")\n",
    "        return None\n",
    "\n",
    "    # Resize and normalize the image\n",
    "    image = cv2.resize(image, (128, 64))  # Resize to match model input\n",
    "    image = image / 255.0  # Normalize\n",
    "\n",
    "    # Predict the text\n",
    "    predicted_label = model.predict(np.expand_dims(image, axis=0))\n",
    "    predicted_text = label_encoder.inverse_transform([np.argmax(predicted_label)])[0]\n",
    "\n",
    "    # Post-process the predicted text\n",
    "    predicted_text = predicted_text.replace(\" \", \"\")  # Remove spaces\n",
    "    return predicted_text\n",
    "\n",
    "# Test on a new image\n",
    "new_image_path = r'C:\\Users\\user\\Desktop\\licplt2.jpg'\n",
    "predicted_text = recognize_license_plate(new_image_path)\n",
    "if predicted_text is not None:\n",
    "    print(f\"Predicted License Plate Text: {predicted_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e80c6f82-6124-4c4a-8391-597c329c6dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the cropped license plate for inspection\n",
    "cv2.imwrite('cropped_license_plate.jpg', image * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3570b94a-1c30-4f7f-91f7-c35cf457127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoder Classes: ['&*5' '&0)Lec' \"'14264\" \"'160 0*; 8806|\" \"'195\" \"'2580\" \"'354820\" \"'3989\"\n",
      " \"'79 3 8612\" \"'9\" \"'MO\" '(165' '(47' '(81 5i' '(9L 35 13651' '(ET' '(j'\n",
      " '010o' '01263*' '01650-7878' '056581]' '0n13-52788]' '0ny 1823' '100'\n",
      " '100+ 5 5333' '1001714' '1018\"; 6950 ' '10335 9640' '104 3' '105 * L1'\n",
      " '105 3*y 9699' '108' '10g9 35 4225' '1103*53517' '110343 6829}'\n",
      " '1116*53668]' '112' '112 + 5633' '113s Z39L' '116 347 3C68' '1163*'\n",
      " '1187' '1190*5 6926' '119032123' '11L O5 239' '120> 89' '121' '123'\n",
      " '125 053 6088 ' '126' '129' '13' '130 2*3 9996' '131' '131* ; 870'\n",
      " '1316 5 40L5]' '132854' '135 07; 4716' '135 _; 5906' '135*4 5332'\n",
      " '13735 8 159' '138 363 1769' '1396' '13oo' '140' '140 3*9 659'\n",
      " '140081714|' '141.356603' '1433' '144_ ' '145 333 1093' '146v2'\n",
      " '1488 52903' '15029 |' '151' '151231866' '152  3567' '152 _; 9438' '1526'\n",
      " '1530*58959' '1558' '156 _' '159' '15}' '160 3*5 5065' '160*794041'\n",
      " '1608754041\"' '1612' '1618-33230' '16264' '164' '164 349' '167* 2142'\n",
      " '1673 5998' '169 19044' '169 _33 9685' '16L' '170 J4 7645' '1708*31077'\n",
      " '1733 59116' '174' '177' '177 3; 4712'\n",
      " '179,0.43747122388793186\\r\\n978.jpg,143,84,339,127,Spel _etra,0.31192722749894625\\r\\n978.jpg,178,170,212,194,[03,0.7576982441947517\\r\\n978.jpg,220,170,302,194,39 1812],0.1184831186017282\\r\\n979.jpg,126,373,230,403,PEUCEOT,0.9448830823801386\\r\\n979.jpg,296,345,517,402,[1458-99128],0.15201831362051604\\r\\n979.jpg,585,367,643,377,42b#,0.01706285960972309\\r\\n981.jpg,220,64,264,94,Ma,0.05940230694197173\\r\\n981.jpg,420,224,466,230,WAIITIII,0.0071380229677989356\\r\\n981.jpg,358,356,466,380,[533658723,0.2902569864077163\\r\\n981.jpg,200,32,261,69,Rbe,0.14128565779281385\\r\\n982.jpg,25,345,97,363,132 +; 820,0.4598683644974303\\r\\n983.jpg,180,64,299,113,Lai,0.07802697049516648\\r\\n983.jpg,162,276,282,304,1886*57083],0.36263766587809015\\r\\n984.jpg,526,332,638,332,02655208],0.08011716486365045\\r\\n985.jpg,155,277,240,302,F87  * 382],0.1561194823332788\\r\\n986.jpg,203,245,356,283,87 +3a8179'\n",
      " '180 0 ; 228' '180 033 228' '180 55 4161' '188 0; 1222' '18833'\n",
      " '192*-46756' '19240' '194 Usy 735' '1J0L' '1l0v1' '1n19' '20' '202'\n",
      " '20834475' '22512 575/' '237' '245451398' '250' '26' '28161 4W7' '288'\n",
      " '3\"ga2714' '30530' '306' '33' '3306062' '34409]' '34982714' '3593'\n",
      " '359778]' '3690' '37' '373 1653' '3819' '3973' '3;' '3TC' '3a>=' '3n'\n",
      " '4034' '4158' '4187' '49' '4Jyi' '5' '5370' '5390' '543' '5567' '573'\n",
      " '5973' '6025 30L4 |' '6070' '6144' '6172' '628 7 9640' '6324]' '6386 _'\n",
      " '65 u >> 8600' '6646 /' '67 _ 50L' '686 7' '6988' '7006' '7055}' '71'\n",
      " '715332' '72 3ny 50L3' '7229' '725.5043' '73019\"' '7355-55906' '74'\n",
      " '7524 6560' '7538' '75543]' '7578' '76' '7708' '7856291' '79' '7^ EU'\n",
      " '80' '8095' '80951' '8179' '87 0*} 8179' '87 5a; 7369' '87 U3' \"8707 '\"\n",
      " '88 1\"; 7703' '88 1;' '89 UAj' '90 Ung' '90 _}' '902 1397' '902-5 4636'\n",
      " '9062]' '91' '91 3; 4293' '91 _i 4293' '92  } 3039' '9240' '93' '9407 ]'\n",
      " '95' '96' '96__oy_3734' '9778' '9848' '9L *; 573' '@as|' '@ocedoo'\n",
      " 'ALiel' 'Aan' 'Arne' 'Aveo L' 'Ax' 'B2792' 'B84_ 352486]' 'BD 55 LBD}'\n",
      " 'BL' 'Ben jdida' 'CADD' 'CITROEN' 'Cg' 'Ciai' 'Clio' 'Cnan' 'DASHQA1+2'\n",
      " 'DOD' 'DOLO' 'DoLi' 'DoLo' 'DoO' 'Dqen' 'DrI' 'E Xarka' 'E06' 'ECOTEC'\n",
      " 'EL]' 'Ee' 'Elngo' 'ElsX' 'F -' 'FF' 'FQRGEST' 'Fei' 'FoLe' 'Gco' 'GoLe'\n",
      " 'HAUARA' 'Hee]' 'Hin' 'ISUZU' 'ISUZu' 'IsuZU' 'J1013>; 3690' 'JSjj?' 'J]'\n",
      " 'JbL' 'Kraiu#n' 'L133 _ ' 'L35' 'L65' 'LE' 'LSDL' 'Lay' 'Lmov'\n",
      " 'M8bs 9630' 'MEGANE' 'MHIN7' 'Mdati' 'N9ls) 558}' 'NAVARA' 'O25' 'ON'\n",
      " 'OPEL' 'Oj' 'Ope' 'Oser' 'PEX' 'Poo' 'Punto' 'QaabtOla' 'RENAUHT'\n",
      " 'RENAULT' 'RENAULT 19' 'SOTUFA' 'Satladet' 'Sinbr 5tevetnouaruar' 'Suzu'\n",
      " 'T1' 'TM' 'Tato' 'ToEN' 'Toyo' 'U*}' 'US' 'UccO ' 'Ucecn' 'UnS' 'Uucaa'\n",
      " 'VECTRA' 'VEMRC' 'VENDRE' 'W132799' 'Waa' 'Wswvi7i' 'Wudd n4s'\n",
      " 'WwWPgloGlasbiccom' 'X' 'YeOL' '[01336950' '[121525 6559' '[122 _ ;2171]'\n",
      " '[1272 59295' '[1276 j4029' '[1343 4413' '[1356- 5332]' '[1380358209'\n",
      " '[13z -28L59' '[1495331332]' '[155&4' '[159\"58894]' '[1673*' '[172 6'\n",
      " '[17734 8953' '[1813 5 9656]' '[1828*36149]' '[1Jb=' '[1Z2H'\n",
      " '[1eeos; 9677 |' '[1o8 735333]' '[233' '[25 43 8583' '[29 +' '[360*98032'\n",
      " '[613893747' '[62 -\"; 9734' '[62 >; 6569]' '[65 64 6646]' '[703 .7842]'\n",
      " '[75252720' '[9227859' '[93|' '[94' '[Tbaelon' '[og'\n",
      " '[unisie-annonce com' 'aaw' 'aba 2' 'abenre' 'anon' 'cGandyy' 'cOanau'\n",
      " 'cOandyy' 'cheUROLET' 'chnozn' 'cllo' 'cua' 'eifd' 'iol_' 'nprt' 'ntact'\n",
      " 'peugEOT' 'tayaratn' 'tunisie-annonce com' 'vdul' '{191 3277' '~bielasI']\n"
     ]
    }
   ],
   "source": [
    "print(\"Label Encoder Classes:\", label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3fc0c6-5852-4fe0-b2e1-c3a976cac0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
